{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oa59x27D_Z73"
      },
      "outputs": [],
      "source": [
        "#@title Install Omnilingual ASR  [Cancel all pop-ups]\n",
        "%cd /content/\n",
        "!rm -rf /content/omnilingual-asr-colab\n",
        "!git clone https://github.com/NeuralFalconYT/omnilingual-asr-colab.git\n",
        "# Uninstall current torch build (probably CUDA 12.6)\n",
        "!pip uninstall -y torch torchaudio\n",
        "# Install the CUDA 12.8 version of PyTorch 2.8.0 (matching fairseq2 requirement)\n",
        "!pip install torch==2.8.0+cu128 torchaudio==2.8.0+cu128 --index-url https://download.pytorch.org/whl/cu128\n",
        "\n",
        "\n",
        "# Omnilingual ASR\n",
        "!pip install fairseq2==0.6\n",
        "!pip install omnilingual-asr==0.1.0\n",
        "\n",
        "# VAD and audio chunking\n",
        "!pip install silero-vad>=4.0.0\n",
        "!pip install onnxruntime>=1.12.0\n",
        "# Text processing\n",
        "!pip install uroman==1.3.1.1\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ‚ö° Run OmniASR Models on Google Colab (Free T4 GPU)\n",
        "\n",
        "You can **run the following models safely on a free Google Colab T4 GPU** üëá\n",
        "\n",
        "| Model                  | Type                              | Parameters | VRAM Usage | ‚úÖ Status on T4 | Description                               |\n",
        "| :--------------------- | :-------------------------------- | :--------- | :--------- | :------------- | :---------------------------------------- |\n",
        "| **`omniASR_CTC_300M`** | CTC ASR                           | 325 M      | ~2 GB      | ‚úÖ Works Fast   | Best balance of speed + accuracy          |\n",
        "| **`omniASR_CTC_1B`**   | CTC ASR                           | 975 M      | ~3 GB      | ‚úÖ Works Well   | High-quality transcription, still fast    |\n",
        "| **`omniASR_LLM_300M`** | LLM ASR (+ language conditioning) | 1.6 B      | ~5 GB      | ‚ö†Ô∏è Borderline  | Works but slower ‚Äî may need smaller batch |\n",
        "| **`omniASR_LLM_1B`**   | LLM ASR (+ language conditioning) | 2.3 B      | ~6 GB      | ‚ö†Ô∏è Possible    | May run with reduced precision (FP16)     |\n",
        "\n",
        "---\n",
        "\n",
        "### üö´ Why You Can‚Äôt Run Bigger Models (3B ‚Äì 7B Versions)\n",
        "\n",
        "> **Colab‚Äôs free T4 GPU only provides ~15 GB total VRAM**, and part of that is already used by the system and PyTorch.\n",
        "\n",
        "| Model            | Parameters     | Est. VRAM Need | ‚ùå Status on T4 | Reason                             |\n",
        "| :--------------- | :------------- | :------------- | :------------- | :--------------------------------- |\n",
        "| `omniASR_CTC_3B` | 3.0 B          | ~8 GB          | ‚ö†Ô∏è Unstable    | May crash or OOM                   |\n",
        "| `omniASR_CTC_7B` | 6.5 B          | ~15 GB         | ‚ùå Too Large    | Exceeds GPU memory                 |\n",
        "| `omniASR_LLM_3B` | 4.4 B          | ~10 GB         | ‚ùå Too Heavy    | T4 not enough VRAM                 |\n",
        "| `omniASR_LLM_7B` | 7.8 B / 7B _ZS | 17 ‚Äì 30 GB     | ‚ùå Impossible   | Requires A100 / RTX 4090 class GPU |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dq6mik2pCrii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Omnilingual ASR\n",
        "%cd /content/omnilingual-asr-colab\n",
        "select_model = \"omniASR_LLM_1B\"  # @param [ \"omniASR_CTC_300M\",\"omniASR_CTC_1B\",\"omniASR_CTC_3B\",\"omniASR_CTC_7B\",\"omniASR_LLM_300M\",\"omniASR_LLM_1B\",\"omniASR_LLM_3B\",\"omniASR_LLM_7B\",\"omniASR_LLM_7B_ZS\"]\n",
        "\n",
        "!python app.py --model $select_model --share --debug"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4IFBxOCjCp-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}